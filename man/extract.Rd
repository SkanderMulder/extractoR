% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/extract.R
\name{extract}
\alias{extract}
\title{Extract structured information from text using LLMs}
\usage{
extract(
  text,
  schema,
  model = "gpt-4o-mini",
  max_retries = 5,
  strategy = c("reflect", "direct", "polite"),
  temperature = 0,
  .progress = TRUE
)
}
\arguments{
\item{text}{A character string containing the unstructured text to extract from.}

\item{schema}{A list defining the desired output structure. This will be
converted into a JSON Schema for validation.
Example: \code{list(title = "character", year = "integer", topics = list("character"))}}

\item{model}{A character string specifying the LLM to use (e.g., "gpt-4o-mini").}

\item{max_retries}{An integer specifying the maximum number of retry attempts
if the LLM initially returns malformed JSON.}

\item{strategy}{A character string specifying the retry strategy:
"reflect" (default, provides detailed feedback to the LLM),
"direct" (sends only errors), or "polite" (a softer request for correction).}

\item{temperature}{A numeric value for the LLM's temperature (0.0 to 1.0).
Lower values make the output more deterministic.}

\item{.progress}{A logical value indicating whether to show progress messages.}
}
\value{
A list containing the extracted and validated information, conforming
to the specified schema.
}
\description{
This is the main function to extract structured information from unstructured
text using a Large Language Model (LLM) and a user-defined schema. It
includes an automatic self-correction loop to ensure the output conforms
to the schema.
}
\examples{
\dontrun{
  # Assuming you have an ellmer API key set up
  # Sys.setenv(ELLMER_API_KEY = "YOUR_API_KEY")

  article_text <- "The quick brown fox jumps over the lazy dog. This is a test article from 2023."
  my_schema <- list(
    main_subject = "character",
    year_published = "integer",
    keywords = list("character")
  )

  result <- extract(
    text = article_text,
    schema = my_schema,
    model = "gpt-4o-mini"
  )

  str(result)

  # Example with Ollama (make sure Ollama is running)
  # result_ollama <- extract(
  #   text = "The new phone has a great camera, but the battery life is poor.",
  #   schema = list(
  #     sentiment = c("positive", "negative", "neutral"),
  #     features = list(list(name = "character", rating = c("good", "bad", "average")))
  #   ),
  #   model = "ollama/gemma:2b"
  # )
}
}
